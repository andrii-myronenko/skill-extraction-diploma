{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a0342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "with open('./data/SkillSpan/json/test.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "flattened_data = []\n",
    "\n",
    "for sentence_idx, entry in enumerate(data):\n",
    "    idx = entry['idx']\n",
    "    source = entry['source']\n",
    "    for token, skill_tag, knowledge_tag in zip(entry['tokens'], entry['tags_skill'], entry['tags_knowledge']):\n",
    "        flattened_data.append({'text_idx': idx, \"sentence_idx\": sentence_idx,  'token': token, 'skill_tag': skill_tag, 'knowledge_tag': knowledge_tag, 'source': source})\n",
    "\n",
    "test_df = pd.DataFrame(flattened_data)\n",
    "test_df['skills_tag_predicted'] = 'O' \n",
    "test_df['knowledge_tag_predicted'] = 'O' \n",
    "\n",
    "\n",
    "test_df = test_df[test_df[\"source\"] == 'tech']\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fa55b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify using JobBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407ed91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "token_skill_classifier = pipeline(model=\"jjzha/jobbert_skill_extraction\", aggregation_strategy=\"first\")\n",
    "token_knowledge_classifier = pipeline(model=\"jjzha/jobbert_knowledge_extraction\", aggregation_strategy=\"first\")\n",
    "\n",
    "df_sentences = test_df.groupby(['text_idx', 'sentence_idx'])['token'].apply(list)\n",
    "df_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9458f6f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def classify_sentence(sentence):\n",
    "    skill_predictions = token_skill_classifier(sentence)\n",
    "    knowledge_predictions = token_knowledge_classifier(sentence)\n",
    "    return skill_predictions, knowledge_predictions\n",
    "\n",
    "\n",
    "def assign_bio_tags(token_list, sentence, predictions, tag_type):\n",
    "    bio_tags = ['O'] * len(token_list)  # Initialize all tokens with 'O'\n",
    "\n",
    "    for pred in predictions:\n",
    "        # Split the predicted span into individual words\n",
    "        predicted_words = pred['word'].split()\n",
    "        num_pred_words = len(predicted_words)\n",
    "        start_idx = None\n",
    "\n",
    "        # Iterate through the tokens to find the matching span\n",
    "        for i in range(len(token_list)):\n",
    "            if token_list[i:i + num_pred_words] == predicted_words:\n",
    "                # Calculate the cumulative length of tokens up to the current index\n",
    "                cumulative_length = sum(len(token) + 1 for token in token_list[:i])  # +1 for space after each token\n",
    "                if cumulative_length == pred['start']:\n",
    "                    start_idx = i\n",
    "                    break\n",
    "\n",
    "        # Assign BIO tags\n",
    "        if start_idx is not None:\n",
    "            for i in range(start_idx, start_idx + num_pred_words):\n",
    "                # Assign 'B' or 'I' based on the entity_group of the prediction\n",
    "                bio_tag = ('B' if pred['entity_group'] == 'B' else 'I')\n",
    "                bio_tags[i] = bio_tag\n",
    "\n",
    "    return bio_tags\n",
    "\n",
    "\n",
    "def update_predictions(tokens_df, sentences_df):\n",
    "    # Iterate through sentences and classify\n",
    "    for (text_idx, sentence_idx), token_list in sentences_df.items():\n",
    "        sentence = ' '.join(token_list)\n",
    "        skill_preds, knowledge_preds = classify_sentence(sentence)\n",
    "        \n",
    "        skill_bio_tags = assign_bio_tags(token_list, sentence, skill_preds, 'Skill')\n",
    "        knowledge_bio_tags = assign_bio_tags(token_list, sentence, knowledge_preds, 'Knowledge')\n",
    "\n",
    "        # Update the DataFrame with BIO tags\n",
    "        for token_idx, (token, skill_tag, knowledge_tag) in enumerate(zip(token_list, skill_bio_tags, knowledge_bio_tags)):\n",
    "            condition = ((tokens_df['text_idx'] == text_idx) & \n",
    "                         (tokens_df['sentence_idx'] == sentence_idx) & \n",
    "                         (tokens_df['token'] == token))\n",
    "            tokens_df.loc[condition, 'skills_tag_predicted'] = skill_tag\n",
    "            tokens_df.loc[condition, 'knowledge_tag_predicted'] = knowledge_tag\n",
    "\n",
    "# Update the DataFrame with predictions\n",
    "update_predictions(test_df, df_sentences)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed55369",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 20)  # or use a specific large number\n",
    "pd.set_option('display.max_columns', 10)  # or use a specific large number\n",
    "\n",
    "print(test_df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a71f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['skill_tag'] = test_df['skill_tag'].apply(lambda x: 'B-Skill' if x == 'B' else ('I-Skill' if x == 'I' else x))\n",
    "test_df['skills_tag_predicted'] = test_df['skills_tag_predicted'].apply(lambda x: 'B-Skill' if x == 'B' else ('I-Skill' if x == 'I' else x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2176d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['knowledge_tag'] = test_df['knowledge_tag'].apply(lambda x: 'B-Knowledge' if x == 'B' else ('I-Knowledge' if x == 'I' else x))\n",
    "test_df['knowledge_tag_predicted'] = test_df['knowledge_tag_predicted'].apply(lambda x: 'B-Knowledge' if x == 'B' else ('I-Knowledge' if x == 'I' else x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc2545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae9dfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('./extracted_skills/test_predicted_job_bert.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddadc3d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m _ \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;129;01mand\u001b[39;00m df\u001b[38;5;241m.\u001b[39mloc[_ \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence_idx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     15\u001b[0m                 file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m create_conll_from_df(test_df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./extracted_skills/test_predicted_job_bert.conll\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_df' is not defined"
     ]
    }
   ],
   "source": [
    "def create_conll_from_df(df, output_path):\n",
    "    with open(output_path, 'w') as file:\n",
    "        for _, row in df.iterrows():\n",
    "            token = row['token']\n",
    "            skill_tag = row['skill_tag']\n",
    "            knowledge_tag = row['knowledge_tag']\n",
    "            skills_tag_predicted = row['skills_tag_predicted']\n",
    "            knowledge_tag_predicted = row['knowledge_tag_predicted']\n",
    "\n",
    "            # Write the token and tags separated by tabs\n",
    "            file.write(f\"1\\t{token}\\t{skill_tag}\\t{knowledge_tag}\\t{skills_tag_predicted}\\t{knowledge_tag_predicted}\\n\")\n",
    "\n",
    "            # Add a new line after each sentence\n",
    "            if _ + 1 in df.index and df.loc[_ + 1, 'sentence_idx'] != row['sentence_idx']:\n",
    "                file.write(\"\\n\")\n",
    "\n",
    "                \n",
    "create_conll_from_df(test_df, './extracted_skills/test_predicted_job_bert.conll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94deae55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRICT: Found: 487 outer and 776 inner phrases; Gold: 440 (outer) and 806 (inner).\n",
      "LOOSE: Found: 487 outer and 776 inner phrases; Gold: 440 (outer) and 806 (inner).\n",
      "\n",
      "1. Strict, Combined Evaluation (official):\n",
      "Accuracy:  95.23%;\n",
      "Precision:  46.56%;\n",
      "Recall:  47.19%;\n",
      "FB1:  46.87\n",
      "\n",
      "2. Loose, Combined Evaluation:\n",
      "Accuracy:  95.23%;\n",
      "Precision:  46.56%;\n",
      "Recall:  47.19%;\n",
      "FB1:  46.87\n",
      "\n",
      "3.1 Per-Level Evaluation (outer chunks):\n",
      "Accuracy:  94.53%;\n",
      "Precision:  36.14%;\n",
      "Recall:  40.00%;\n",
      "FB1:  37.97\n",
      "\n",
      "3.2 Per-Level Global Evaluation (inner chunks):\n",
      "Accuracy:  95.92%;\n",
      "Precision:  53.09%;\n",
      "Recall:  51.12%;\n",
      "FB1:  52.09\n",
      "\n",
      "\n",
      "Evaluation per type and mode:\n",
      "=============================\n",
      "\n",
      "==>  Knowledge\n",
      "==============\n",
      "Outer strict: Precision:   0.00%; Recall:   0.00%; FB1:   0.00\n",
      "Inner strict: Precision:  53.09%; Recall:  51.12%; FB1:  52.09\n",
      "Outer loose: Precision:   0.00%; Recall:   0.00%; FB1:   0.00\n",
      "Inner loose: Precision:  53.09%; Recall:  51.12%; FB1:  52.09\n",
      "==>      Skill\n",
      "==============\n",
      "Outer strict: Precision:  36.14%; Recall:  40.00%; FB1:  37.97\n",
      "Inner strict: Precision:   0.00%; Recall:   0.00%; FB1:   0.00\n",
      "Outer loose: Precision:  36.14%; Recall:  40.00%; FB1:  37.97\n",
      "Inner loose: Precision:   0.00%; Recall:   0.00%; FB1:   0.00\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "out = os.popen(\n",
    "    f\"perl nereval.perl < ./extracted_skills/test_predicted_job_bert.conll\"\n",
    ").read()\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156dfdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now let's try to do the same with LLMs\n",
    "\n",
    "# We will have several prompts for the detection of skills and knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0a6e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tech_df_merged = pd.read_csv('./data/merged/test_df_tech_only.csv')\n",
    "\n",
    "test_tech_df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df4668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose_template = \"\"\"\n",
    "You are a top-notch recruiter and data labeler.\n",
    "Your task is to thoroughly analyze the following part of a job posting and extract text spans including skills or knowledge.\n",
    "\n",
    "You should use the following guideline for annotation:\n",
    "\n",
    "Instruction for Annotating Text for Skills and Knowledge Components\n",
    "Objective: Identify and annotate spans of text in job postings (JPs) that represent specific skills or knowledge required for the position.\n",
    "\n",
    "1. Identifying Skills:\n",
    "\n",
    "General Rule: A skill is usually indicated by a VERB or an (ADJECTIVE) + NOUN combination.\n",
    "Exclusion of Modal Verbs: Do not tag modal verbs (e.g., can, will) as part of the skill.\n",
    "Phrase Separation: Split phrases containing prepositions and/or conjunctions, except when conjunctions coordinate two nouns as a single argument.\n",
    "Handling Anaphoric Pronouns: Avoid tagging skills with anaphoric pronouns. Only tag the preceding skill.\n",
    "Splitting Coordinated Components: Split nouns and adjectives in coordination if they lack a verb.\n",
    "Listing of Skills: If skills are listed leading to different subtasks, annotate each separately.\n",
    "Brevity in Contextual Information: Keep skill annotations concise, especially when followed by company-specific info.\n",
    "Inclusion of 'skills' or 'knowledge' in Tags: Include these words in the annotation if their omission alters the meaning.\n",
    "Parenthetical Information: Include if it elaborates on the skill or is an abbreviation.\n",
    "Adverbial Inclusion: Include adverbials that describe the manner of doing something.\n",
    "Attitudes as Skills: Annotate attitudes as skills, omitting articles.\n",
    "Exclusions:\n",
    "Avoid tagging ironic skills.\n",
    "Avoid nested annotations; use one span for overlapping skills.\n",
    "Do not tag skills in top headlines, but do tag in sub-headlines and body text.\n",
    "Exclude fluff and triggers surrounding the skill component.\n",
    "Exclude participation, contributing, and transfer expressions from skill annotations.\n",
    "Do not annotate occupations or positions.\n",
    "Focus on skills related and specific to the position.\n",
    "\n",
    "2. Identifying Knowledge:\n",
    "General Rule: Knowledge is non-executable and possessed by an individual.\n",
    "Inclusion of Parenthetical Information: Include if it is related to the knowledge component.\n",
    "Licenses and Certifications: Include additional words like \"certificate,\" \"license,\" etc.\n",
    "Vague Preceding Verbs: Only tag the knowledge component if preceded by a vague verb.\n",
    "Specificity: Annotate only specified knowledge components.\n",
    "Nested Knowledge in Skills: Knowledge components can be nested within skill annotations.\n",
    "Coordination of Knowledge Components: Annotate as one if all components share one knowledge tag.\n",
    "Listing Knowledge Tags: Annotate all knowledge tags separately.\n",
    "Annotation of Industries and Fields: Tag these as knowledge components.\n",
    "\n",
    "3. Prioritization and Other Considerations:\n",
    "Prefer skills over knowledge in uncertain cases.\n",
    "Prioritize skills over attitudes; only tag the skill within an attitude.\n",
    "Keep annotations concise and relevant to the job.\n",
    "Annotate skills and knowledge in unconventional places if related to the position.\n",
    "Consider annotating a combination of skill and knowledge when applicable.\n",
    "Exclude knowledge/skill components in positions.\n",
    "Focus on annotations relevant to the specific position and its future expectations.\n",
    "\n",
    "Output just the JSON array, wihtout any other text. \n",
    "Start your response with \"[\" symbol, and finish with \"]\".\n",
    "Make sure your response doesn't include anything else.\n",
    "\n",
    "Job posting:\n",
    "{job_posting}\n",
    "\n",
    "Response:\"\"\"\n",
    "\n",
    "short_template = \"\"\"\n",
    "    You are a top-notch recruiter and data labeler.\n",
    "    Your task is to thoroughly analyze the following part of a job posting and extract text spans including skills and knowledge.\n",
    "    A skill in a job context is typically indicated by a verb or an adjective-noun combination, reflecting an executable ability or a specific way of performing a task. \n",
    "    Knowledge, on the other hand, refers to non-executable information that an individual possesses, often indicated by specific fields, industries, or certifications, and is distinct from direct action or skills.\n",
    "\n",
    "    Output the JSON array, wihtout any other text. \n",
    "    Start your response with \"[\" symbol, and finish with \"]\".\n",
    "    Make sure your response doesn't include anything else.\n",
    "        \n",
    "    Job posting:\n",
    "    {job_posting}\n",
    "\"\"\"\n",
    "\n",
    "few_shot_template = \"\"\"\n",
    "    You are a top-notch recruiter and data labeler.\n",
    "    Your task is to thoroughly analyze the following part of a job posting and extract text spans including job-related skills or knowledge.\n",
    "    A skill in a job context is typically indicated by a verb or an adjective-noun combination, reflecting an executable ability or a specific way of performing a task. \n",
    "    Knowledge, on the other hand, refers to non-executable information that an individual possesses, often indicated by specific fields, industries, or certifications, and is distinct from direct action or skills.\n",
    "    \n",
    "    Below you can see some examples. Pay attention to what is included in detected spans. We want not to include false positive skills and knowledge.\n",
    "\n",
    "    Job posting:\n",
    "    Ability to work in large collaborative teams to achieve organizational goals\n",
    "    Detected spans:\n",
    "    [\"work in large collaborative teams\"]\n",
    "\n",
    "    Job posting:\n",
    "    Work hands-on together with the other engineers within the Agile team \n",
    "    Detected spans:\n",
    "    [\"Work hands-on\"]\n",
    "    \n",
    "    Job posting:\n",
    "    Requirements At least 5 years of combined experience in Java or Kotlin and JavaScript or TypeScript programming and related test frameworks ( Selenium TestCafe etc.) .\n",
    "    Detected spans:\n",
    "    [\"Java\", \"Kotlin\", \"JavaScript\", \"Typescript\"]\n",
    "    \n",
    "    Job posting:\n",
    "    A degree in Computer Science or related fields or equivalent practical experience . \n",
    "    Detected spans:\n",
    "    [\"degree in Computer Science\"]\n",
    "    \n",
    "    Job posting:\n",
    "    Experience in working on a cloud-based application running on Docker .\n",
    "    Detected spans:\n",
    "    [\"Docker\", \"working on a cloud-based application\"]\n",
    "    \n",
    "    Make sure to never include protected attributes like gender identity or veteran status in the returned list:\n",
    "    \n",
    "    Job posting:\n",
    "    We do not discriminate on the basis of any protected attribute including race religion color national origin gender sexual orientation .\n",
    "    Detected spans:\n",
    "    []\n",
    "\n",
    "    Output just the JSON array, wihtout any other text. \n",
    "    Start your response with \"[\" symbol, and finish with \"]\".\n",
    "    Make sure your response doesn't include data from examples and anything else except from JSON array.\n",
    "    Return empty array If there are no obvious skill and knowledge spans in the given posting.\n",
    "    \n",
    "    Job posting:\n",
    "    {job_posting}\n",
    "    Detected spans:\n",
    "\"\"\"\n",
    "\n",
    "template_collection = {\n",
    "    'verbose': verbose_template,\n",
    "    'short': short_template,\n",
    "    'few_shot': few_shot_template\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f6ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=[\"job_posting\"], template=template_collection['few_shot'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skill-extraction-env",
   "language": "python",
   "name": "skill-extraction-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
