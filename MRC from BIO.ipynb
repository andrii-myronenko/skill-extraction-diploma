{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94e5b7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/andriimyronenko/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75b5390e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev DataFrame:\n",
      "   idx                                             tokens  \\\n",
      "0    1  [DevOps, Engineer, (, CI, CD, Cloud, Docker, J...   \n",
      "1    1  [<ADDRESS>, <ADDRESS>, <LOCATION>, -, <LOCATION>]   \n",
      "2    1                        [Date, posted:, 2021-04-22]   \n",
      "3    1                [Likes:, 0, Dislikes:, 0, Love:, 0]   \n",
      "4    1                                [Job, description:]   \n",
      "\n",
      "                       tags_skill                  tags_knowledge source  \n",
      "0  [O, O, O, O, O, O, O, O, O, O]  [O, O, O, O, O, O, O, O, O, O]   tech  \n",
      "1                 [O, O, O, O, O]                 [O, O, O, O, O]   tech  \n",
      "2                       [O, O, O]                       [O, O, O]   tech  \n",
      "3              [O, O, O, O, O, O]              [O, O, O, O, O, O]   tech  \n",
      "4                          [O, O]                          [O, O]   tech  \n",
      "\n",
      "Train DataFrame:\n",
      "   idx                                             tokens  \\\n",
      "0    1  [Senior, QA, Engineer, (, m/f/d, ), <ORGANIZAT...   \n",
      "1    1  [<ADDRESS>, <ADDRESS>, <ADDRESS>, <ADDRESS>, <...   \n",
      "2    1                        [Date, posted:, 2021-07-14]   \n",
      "3    1                [Likes:, 0, Dislikes:, 0, Love:, 0]   \n",
      "4    1                                [Job, description:]   \n",
      "\n",
      "              tags_skill         tags_knowledge source  \n",
      "0  [O, O, O, O, O, O, O]  [O, O, O, O, O, O, O]   tech  \n",
      "1        [O, O, O, O, O]        [O, O, O, O, O]   tech  \n",
      "2              [O, O, O]              [O, O, O]   tech  \n",
      "3     [O, O, O, O, O, O]     [O, O, O, O, O, O]   tech  \n",
      "4                 [O, O]                 [O, O]   tech  \n",
      "\n",
      "Test DataFrame:\n",
      "   idx                                             tokens  \\\n",
      "0    1  [Full, Stack, Software, Engineer, -, Java, /, ...   \n",
      "1    1  [<ORGANIZATION>, <ORGANIZATION>, <ORGANIZATION...   \n",
      "2    1  [<ADDRESS>, <ADDRESS>, <LOCATION>, -, <LOCATION>]   \n",
      "3    1                        [Date, posted:, 2021-03-04]   \n",
      "4    1                [Likes:, 0, Dislikes:, 0, Love:, 0]   \n",
      "\n",
      "                 tags_skill            tags_knowledge source  \n",
      "0  [O, O, O, O, O, O, O, O]  [O, O, O, O, O, O, O, O]   tech  \n",
      "1           [O, O, O, O, O]           [O, O, O, O, O]   tech  \n",
      "2           [O, O, O, O, O]           [O, O, O, O, O]   tech  \n",
      "3                 [O, O, O]                 [O, O, O]   tech  \n",
      "4        [O, O, O, O, O, O]        [O, O, O, O, O, O]   tech  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "base_path = 'data/SkillSpan/json/'\n",
    "file_names = ['dev.json', 'train.json', 'test.json']\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "for file_name in file_names:\n",
    "    file_path = base_path + file_name\n",
    "    with open(file_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "        dfs[file_name.split('.')[0]] = pd.DataFrame(json_data)\n",
    "\n",
    "dev_df = dfs['dev']\n",
    "train_df = dfs['train']\n",
    "test_df = dfs['test']\n",
    "\n",
    "print(\"Dev DataFrame:\")\n",
    "print(dev_df.head())\n",
    "\n",
    "print(\"\\nTrain DataFrame:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nTest DataFrame:\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1101b80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags_skill</th>\n",
       "      <th>tags_knowledge</th>\n",
       "      <th>source</th>\n",
       "      <th>part</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[DevOps, Engineer, (, CI, CD, Cloud, Docker, J...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>tech</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[&lt;ADDRESS&gt;, &lt;ADDRESS&gt;, &lt;LOCATION&gt;, -, &lt;LOCATION&gt;]</td>\n",
       "      <td>[O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O]</td>\n",
       "      <td>tech</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[Date, posted:, 2021-04-22]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>tech</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[Likes:, 0, Dislikes:, 0, Love:, 0]</td>\n",
       "      <td>[O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O]</td>\n",
       "      <td>tech</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[Job, description:]</td>\n",
       "      <td>[O, O]</td>\n",
       "      <td>[O, O]</td>\n",
       "      <td>tech</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                                             tokens  \\\n",
       "0    1  [DevOps, Engineer, (, CI, CD, Cloud, Docker, J...   \n",
       "1    1  [<ADDRESS>, <ADDRESS>, <LOCATION>, -, <LOCATION>]   \n",
       "2    1                        [Date, posted:, 2021-04-22]   \n",
       "3    1                [Likes:, 0, Dislikes:, 0, Love:, 0]   \n",
       "4    1                                [Job, description:]   \n",
       "\n",
       "                       tags_skill                  tags_knowledge source part  \n",
       "0  [O, O, O, O, O, O, O, O, O, O]  [O, O, O, O, O, O, O, O, O, O]   tech  dev  \n",
       "1                 [O, O, O, O, O]                 [O, O, O, O, O]   tech  dev  \n",
       "2                       [O, O, O]                       [O, O, O]   tech  dev  \n",
       "3              [O, O, O, O, O, O]              [O, O, O, O, O, O]   tech  dev  \n",
       "4                          [O, O]                          [O, O]   tech  dev  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df['part'] = 'dev'\n",
    "train_df['part'] = 'train'\n",
    "test_df['part'] = 'test'\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "combined_df = pd.concat([dev_df, train_df, test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d95f8601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bio_tags_to_spans(bio_tags):\n",
    "    \"\"\"\n",
    "    Convert a list of BIO tags into a list of spans, where each span is a pair\n",
    "    (start, end) representing where an entity starts and ends in the token list.\n",
    "\n",
    "    Parameters:\n",
    "    - bio_tags: A list of strings, the BIO tags for each token in a sequence.\n",
    "\n",
    "    Returns:\n",
    "    - A list of tuples, each representing the start and end indices of entities.\n",
    "    \"\"\"\n",
    "    spans = []\n",
    "    start, end = None, None\n",
    "\n",
    "    for i, tag in enumerate(bio_tags):\n",
    "        if tag.startswith('B'):  # Beginning of an entity\n",
    "            if start is not None:\n",
    "                # End the previous entity\n",
    "                spans.append((start, end))\n",
    "            start, end = i, i  # Start a new entity\n",
    "        elif tag.startswith('I') and start is not None:\n",
    "            # Inside an entity\n",
    "            end = i\n",
    "        else:\n",
    "            # Outside of an entity\n",
    "            if start is not None:\n",
    "                # End the current entity\n",
    "                spans.append((start, end))\n",
    "                start, end = None, None\n",
    "\n",
    "    # Add the last entity if the sentence ends with an entity\n",
    "    if start is not None:\n",
    "        spans.append((start, end))\n",
    "\n",
    "    return spans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4c7df38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_entity(index, row, entity_label, accumulator):\n",
    "    secondary_idx = 0 if entity_label == \"SKL\" else 1\n",
    "    qas_id = f\"{index}.{secondary_idx}\"\n",
    "    context = ' '.join(row['tokens'])\n",
    "    \n",
    "    biotag_column = \"tags_skill\" if entity_label == \"SKL\" else \"tags_knowledge\"\n",
    "    biotags = row[biotag_column]\n",
    "    bio_spans = bio_tags_to_spans(biotags)\n",
    "    end_position = []\n",
    "    span_position = []\n",
    "    start_position = []\n",
    "\n",
    "    for start, end in bio_spans:\n",
    "        start_position.append(start)\n",
    "        end_position.append(end)\n",
    "        span_position.append(f\"{start};{end}\")\n",
    "        \n",
    "    entity_dict = {\n",
    "        \"context\": context,\n",
    "        \"entity_label\": entity_label,\n",
    "        \"qas_id\": qas_id,\n",
    "        \"end_position\": end_position,\n",
    "        \"span_position\": span_position,\n",
    "        \"start_position\": start_position,\n",
    "        \"source\": row[\"source\"],\n",
    "        \"part\": row[\"part\"]\n",
    "    }\n",
    "    \n",
    "    accumulator.append(entity_dict)\n",
    "\n",
    "def process_row(index, row, accumulator):\n",
    "    process_entity(index, row, \"SKL\", accumulator);\n",
    "    process_entity(index, row, \"KNG\", accumulator);\n",
    "    \n",
    "def process_dataframe(df):\n",
    "    accumulator = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        process_row(index, row, accumulator);\n",
    "\n",
    "    return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5e029211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23086"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrc_list = process_dataframe(combined_df)\n",
    "\n",
    "len(mrc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7f9c4dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15948"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrc_train = [obj for obj in mrc_list if obj.get(\"part\") != \"test\"]\n",
    "\n",
    "len(mrc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "992a98ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7138"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrc_test = [obj for obj in mrc_list if obj.get(\"part\") == \"test\"]\n",
    "\n",
    "len(mrc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ec7e9263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(path, json_data):\n",
    "    with open(path, 'w') as file:\n",
    "        json.dump(json_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "23de869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file('./data/merged/mrc-ner.test.all', mrc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a087fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file('./data/merged/mrc-ner.train.all', mrc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ded725c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10578"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrc_train_tech = [obj for obj in mrc_list if obj.get(\"part\") != \"test\" and obj.get(\"source\") == \"tech\"]\n",
    "\n",
    "len(mrc_train_tech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "18947539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4572"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrc_test_tech = [obj for obj in mrc_list if obj.get(\"part\") == \"test\" and obj.get(\"source\") == \"tech\"]\n",
    "\n",
    "len(mrc_test_tech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c8299f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file('./data/merged/mrc-ner.test.tech', mrc_test_tech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "220aff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file('./data/merged/mrc-ner.train.tech', mrc_train_tech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b84a8119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5370"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrc_train_house = [obj for obj in mrc_list if obj.get(\"part\") != \"test\" and obj.get(\"source\") == \"house\"]\n",
    "\n",
    "len(mrc_train_house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5cd466be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2566"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrc_test_house = [obj for obj in mrc_list if obj.get(\"part\") == \"test\" and obj.get(\"source\") == \"house\"]\n",
    "\n",
    "len(mrc_test_house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c252c8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file('./data/merged/mrc-ner.test.house', mrc_test_house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "386b70b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file('./data/merged/mrc-ner.train.house', mrc_train_house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c97025ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2993"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_items_with_spans = [item for item in mrc_train if item.get(\"span_position\")]\n",
    "\n",
    "len(train_items_with_spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3a49ebca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1095"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_items_with_spans = [item for item in mrc_test if item.get(\"span_position\")]\n",
    "\n",
    "len(test_items_with_spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "10f5c69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random_train = random.sample(train_items_with_spans, min(len(mrc_train), 100))\n",
    "random_test = random.sample(test_items_with_spans, min(len(mrc_train), 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "78fdbe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file('./data/merged/mrc-ner.test.random', random_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ac0fe836",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file('./data/merged/mrc-ner.train.random', random_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skill-extraction-env",
   "language": "python",
   "name": "skill-extraction-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
